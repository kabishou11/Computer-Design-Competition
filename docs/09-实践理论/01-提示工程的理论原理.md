# 第二章：提示工程的理论原理

## 2.1 提示的本质

### 2.1.1 提示作为条件化

大语言模型本质是**条件概率分布**：

$$P(w | \text{prompt})$$

提示的作用是**条件化**模型的输出。

### 2.1.2 上下文学习（In-Context Learning）

**定义**：

在不更新参数的情况下，通过提示中的示例学习新任务。

**数学表达**：

$$\hat{y} = f(x; \theta, \text{prompt})$$

其中 $\theta$ 固定，只改变 $\text{prompt}$。

### 2.1.3 提示工程的目标

1. **激发模型能力**：让模型展示其学到的知识
2. **引导输出格式**：获得期望的输出形式
3. **减少幻觉**：通过提示约束模型

## 2.2 提示的组成要素

### 2.2.1 任务描述

**作用**：明确告诉模型要做什么

**原则**：
- 具体而非模糊
- 使用命令式语气
- 明确输出格式

**示例对比**：

| 差 | 好 |
|-----|-----|
| 分析这个问题 | 请分析以下问题的原因、影响和解决方案 |
| 写代码 | 请用Python实现XXX功能，包括函数定义、参数说明和错误处理 |

### 2.2.2 上下文信息

**作用**：提供背景知识

**类型**：
- 领域知识
- 相关数据
- 历史对话

### 2.2.3 输入数据

**作用**：需要处理的具体内容

**格式**：
- 清晰分隔输入
- 使用标记区分

### 2.2.4 输出格式

**作用**：指定期望的输出形式

**常用格式**：
- JSON
- Markdown表格
- 列表
- 步骤说明

## 2.3 提示策略

### 2.3.1 少样本学习（Few-Shot）

**格式**：

```markdown
任务：根据情感分类

示例1：这部电影太棒了！→ 正面
示例2：服务态度很差，差评。→ 负面
示例3：一般般，没有惊喜。→ 中性

输入：这个产品还不错，值得购买。
输出：
```

**示例选择策略**：

1. **多样性**：覆盖不同类型
2. **相似性**：与目标输入相似
3. **数量**：通常2-5个为宜

### 2.3.2 思维链（Chain-of-Thought）

**核心思想**：

让模型展示推理过程，而非直接给出答案。

**格式**：

```markdown
问题：小明有5个苹果，丢了2个，又买了3个，现在有几个？

推理过程：
1. 初始：5个苹果
2. 丢了2个：5-2=3个
3. 买了3个：3+3=6个
最终答案：6个
```

**为什么有效**：

1. **分配计算**：将复杂计算分步
2. **减少错误**：每步验证
3. **可解释**：展示中间过程

### 2.3.3 自洽性（Self-Consistency）

**原理**：

对同一问题多次采样，取最一致的答案。

**步骤**：
1. 多次生成推理路径
2. 统计各答案的频率
3. 选择频率最高的答案

### 2.3.4 提示模板

**结构化模板**：

```markdown
# 角色定义
你是一个[专业角色]。

# 任务说明
你的任务是[具体任务]。

# 背景知识
[领域背景]

# 输出格式
请按以下格式输出：
1. [格式要求1]
2. [格式要求2]

# 开始任务
[具体输入]
```

## 2.4 提示调优

### 2.4.1 A/B测试

对不同提示进行对比实验：

| 提示 | 准确率 |
|-----|-------|
| 基础提示 | 65% |
| 添加角色定义 | 72% |
| 添加示例 | 78% |
| 完整模板 | 82% |

### 2.4.2 自动提示优化

**APE（Automatic Prompt Engineer）**：

1. 生成候选提示
2. 评估效果
2. 选择最优提示

### 2.4.3 提示质量评估

**维度**：

1. **清晰度**：表述是否明确
2. **完整性**：是否涵盖所有要点
3. **有效性**：是否达到预期效果

## 2.5 提示工程理论

### 2.5.1 注意力视角

提示通过**注意力机制**影响模型：

- 提示中的关键词获得更高注意力
- 示例提供了任务的"注意力模式"

### 2.5.2 贝叶斯视角

提示更新了模型对输出的**先验分布**：

$$P(y | x, \text{prompt}) \propto P(\text{prompt} | y) P(y)$$

### 2.5.3 计算视角

复杂任务需要**更多计算资源**：

- CoT增加了生成长度（更多计算）
- 自洽性多次采样（更多计算）

## 2.6 本章小结

| 策略 | 原理 | 适用场景 |
|-----|------|---------|
| 少样本 | 提供示例 | 格式学习 |
| CoT | 展示推理 | 复杂计算 |
| 自洽性 | 多次采样 | 减少错误 |
| 角色定义 | 条件化 | 领域适应 |

**核心观点**：

1. 提示是激活模型能力的杠杆
2. 好的提示需要精心设计
3. 不同任务需要不同策略
