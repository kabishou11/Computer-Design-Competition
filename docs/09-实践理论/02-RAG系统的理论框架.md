# 第三章：RAG系统的理论框架

## 3.1 RAG的理论基础

### 3.1.1 记忆理论

**双重记忆理论**（Atkinson & Shiffrin, 1968）：

```
┌─────────────────────────────────────────┐
│              感官记忆                    │
│         （短暂，输入立即流失）             │
└────────────────┬────────────────────────┘
                 │
                 ▼
┌─────────────────────────────────────────┐
│              短期记忆                    │
│       （容量有限，7±2项目）             │
└────────────────┬────────────────────────┘
                 │
                 ▼
┌─────────────────────────────────────────┐
│              长期记忆                    │
│       （容量无限，永久存储）             │
└─────────────────────────────────────────┘
```

**RAG作为外部记忆**：

- **参数记忆**：模型训练时学到的知识
- **检索记忆**：RAG从外部获取的知识

### 3.1.2 检索理论

**精确匹配 vs 语义匹配**

| 类型 | 方法 | 特点 |
|-----|------|------|
| 精确匹配 | 关键词检索 | 字面匹配，不处理同义词 |
| 语义匹配 | 向量检索 | 语义相近即可匹配 |

**向量检索的数学基础**：

$$sim(q, d) = \frac{q \cdot d}{|q||d|}$$

这是余弦相似度，衡量两个向量的方向相似性。

## 3.2 检索质量分析

### 3.2.1 检索指标

**召回率（Recall）**：

$$Recall@K = \frac{|\text{relevant} \cap \text{retrieved@K}|}{|\text{relevant}|}$$

衡量检索系统找到相关文档的能力。

**精确率（Precision）**：

$$Precision@K = \frac{|\text{relevant} \cap \text{retrieved@K}|}{K}$$

衡量检索结果的相关程度。

**MRR（Mean Reciprocal Rank）**：

$$MRR = \frac{1}{N}\sum_{i=1}^{N}\frac{1}{rank_i}$$

衡量第一个相关文档的排名位置。

### 3.2.2 检索失败模式

| 模式 | 原因 | 解决方案 |
|-----|------|---------|
| 语义漂移 | 查询和文档语义不匹配 | 查询改写 |
| 关键词不匹配 | 同义词/缩写 | 混合检索 |
| 排序不准 | 相似度计算不准确 | 重排序 |
| 冷启动 | 新领域无数据 | 领域适配 |

## 3.3 检索与生成的交互

### 3.3.1 生成模型的条件化

**数学表达**：

$$P(y | x, R) = \sum_{d \in R} P(y | x, d) P(d | x)$$

其中：
- $x$：输入查询
- $R$：检索结果
- $d$：单个文档
- $P(d | x)$：检索概率

### 3.3.2 上下文窗口利用

**有效信息量**：

$$\text{Effective Info} = \sum_{i=1}^{K} \alpha_i \cdot I(d_i)$$

其中 $\alpha_i$ 是第 $i$ 个文档的注意力权重。

### 3.3.3 噪声影响

检索结果包含噪声时，生成质量会下降：

$$P(y | x) = \sum_{d \in R} w_d P(y | x, d)$$

$w_d$ 是检索权重，受噪声影响。

## 3.4 RAG优化理论

### 3.4.1 检索优化

**查询优化**：

$$q^* = \arg\max_q \sum_{d \in D} P(d | q) \cdot \text{relevance}(q, d)$$

目标是找到能检索到高质量文档的查询。

**文档优化**：

- 内容质量
- 分块策略
- 元数据增强

### 3.4.2 融合优化

**重排序**：

$$score(d | q) = \lambda \cdot sim_{semantic}(q, d) + (1-\lambda) \cdot sim_{keyword}(q, d)$$

### 3.4.3 生成优化

**上下文压缩**：

$$\text{compressed}(C) = f(C, q)$$

移除与查询无关的上下文。

## 3.5 RAG评估理论

### 3.5.1 检索评估

**Hit Rate**：

$$Hit@K = \mathbb{I}(\text{至少有一个相关文档在top-K})$$

### 3.5.2 生成评估

**Faithfulness（忠实度）**：

衡量生成内容与检索内容的**一致性**。

**Answer Relevance（答案相关性）**：

衡量答案与问题的**相关性**。

### 3.5.3 端到端评估

**RAGAs指标**：

| 指标 | 定义 | 范围 |
|-----|------|------|
| Faithfulness | 答案与上下文的一致程度 | [0, 1] |
| Answer Relevancy | 答案与问题的相关程度 | [0, 1] |
| Context Precision | 检索质量的精度 | [0, 1] |
| Context Recall | 检索质量的召回 | [0, 1] |

## 3.6 本章小结

**核心观点**：

1. RAG模拟了人类记忆系统
2. 检索质量直接影响生成效果
3. 检索与生成需要协同优化
4. 评估需要多维度考量

**理论框架**：

$$RAG = \text{Retrieve}(x) + \text{Context}(R) + \text{Generate}(x, R)$$

理解这个框架有助于设计更好的RAG系统。
